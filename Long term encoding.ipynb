{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aa91cf34-d9d4-4e9b-8332-79cf2c93f0e0",
   "metadata": {},
   "source": [
    "# Long-term encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "016caacd-6b38-4f98-a5be-ed278427db8e",
   "metadata": {},
   "source": [
    "### Set-up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "97056e3f-064e-4a18-b938-121272eedf55",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "from importlib import reload \n",
    "\n",
    "import syntactic_wm as cjn ## Our model\n",
    "reload(cjn)\n",
    "\n",
    "\n",
    "################\n",
    "## Parameters ##\n",
    "################\n",
    "num_steps = 50 # number of time steps taken by each word input.\n",
    "head = 1 # number of time steps buffering the front of each sentence.\n",
    "tail = 20 # number of time steps buffering the end of each sentence.\n",
    "no_periods = 30 # number of epochs each sentence is presented to the model.\n",
    "\n",
    "tau = 0.5 # modifies change in firing rate at each time step to simulate continuous time.\n",
    "\n",
    "beta = 1 # decay factor of firing rates.\n",
    "\n",
    "n_word_neurons = 15 # number of word neurons initialised (f)\n",
    "n_role_neurons = 10 # number of role neurons initialised (c)\n",
    "\n",
    "gamma = 0.5 # factor dampening connectivity amongst role neurons.\n",
    "\n",
    "epsilon_cc = 6 # the ceiling of c-c connections when without long-term encoding, while taking into account of negative bias k. \n",
    "k_cc = 5 # negative bias, i.e. negative k_cc is the floor of c-c connections.\n",
    "\n",
    "epsilon_cf = 3 # the ceiling of c-f connections when without long-term encoding, while taking into account of negative bias k. \n",
    "k_cf = 1 # negative bias, i.e. negative k_cf is the floor of c-f connections.\n",
    "\n",
    "h = 2 # normalising factor for inhibition between c-f connections.\n",
    "\n",
    "W_mc = 5.6 # connectivity between morph and role neurons (non-encodable)\n",
    "W_mm = -10 # conneectivity between morpheme neurons to itself (non-encodable)\n",
    "\n",
    "W_ff = -0.5  # connectivity amongst word neurons (non-encodable)\n",
    "\n",
    "unified_noise = 0 # noise level if noise is present\n",
    "cc_noise = False # any noise amongst role neurons\n",
    "wc_noise = False # any noise between role and word neurons\n",
    "\n",
    "k_L_cc = 5.7 # long-term encoding amongst role neurons \n",
    "k_L_cf = 1.7 # long-term encoding between role and word neurons\n",
    "\n",
    "# random seed only helpful during long-term acquisition of syntactic knowledge\n",
    "seed_ = 0 # setting default random seed\n",
    "np.random.seed(seed_)\n",
    "random.seed(seed_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53213a90-0eb0-4261-ab7d-ba19914e5054",
   "metadata": {},
   "source": [
    "### Pivot Grammar for long-term word-to-role encoding\n",
    "\n",
    "In the first part of long-term knowledge acquisition, we make use of pivot grammar to acquire long-term encodings for word-to-role encodings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fd856f32-a79c-46fd-9a2f-f27592aea81a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********************\n",
      "Epoch = 1\n",
      "Number of recorded time steps:  121\n",
      "********************\n",
      "Epoch = 2\n",
      "Number of recorded time steps:  242\n",
      "********************\n",
      "Epoch = 3\n",
      "Number of recorded time steps:  363\n",
      "********************\n",
      "Epoch = 4\n",
      "Number of recorded time steps:  484\n",
      "********************\n",
      "Epoch = 5\n",
      "Number of recorded time steps:  605\n",
      "********************\n",
      "Epoch = 6\n",
      "Number of recorded time steps:  726\n",
      "********************\n",
      "Epoch = 7\n",
      "Number of recorded time steps:  847\n",
      "********************\n",
      "Epoch = 8\n",
      "Number of recorded time steps:  968\n",
      "********************\n",
      "Epoch = 9\n",
      "Number of recorded time steps:  1089\n",
      "********************\n",
      "Epoch = 10\n",
      "Number of recorded time steps:  1210\n",
      "********************\n",
      "********************\n",
      "Epoch = 11\n",
      "Number of recorded time steps:  1331\n",
      "********************\n",
      "Epoch = 12\n",
      "Number of recorded time steps:  1452\n",
      "********************\n",
      "Epoch = 13\n",
      "Number of recorded time steps:  1573\n",
      "********************\n",
      "Epoch = 14\n",
      "Number of recorded time steps:  1694\n",
      "********************\n",
      "Epoch = 15\n",
      "Number of recorded time steps:  1815\n",
      "********************\n",
      "Epoch = 16\n",
      "Number of recorded time steps:  1936\n",
      "********************\n",
      "Epoch = 17\n",
      "Number of recorded time steps:  2057\n",
      "********************\n",
      "Epoch = 18\n",
      "Number of recorded time steps:  2178\n",
      "********************\n",
      "Epoch = 19\n",
      "Number of recorded time steps:  2299\n",
      "********************\n",
      "Epoch = 20\n",
      "Number of recorded time steps:  2420\n",
      "********************\n",
      "********************\n",
      "Epoch = 21\n",
      "Number of recorded time steps:  2541\n",
      "********************\n",
      "Epoch = 22\n",
      "Number of recorded time steps:  2662\n",
      "********************\n",
      "Epoch = 23\n",
      "Number of recorded time steps:  2783\n",
      "********************\n",
      "Epoch = 24\n",
      "Number of recorded time steps:  2904\n",
      "********************\n",
      "Epoch = 25\n",
      "Number of recorded time steps:  3025\n",
      "********************\n",
      "Epoch = 26\n",
      "Number of recorded time steps:  3146\n",
      "********************\n",
      "Epoch = 27\n",
      "Number of recorded time steps:  3267\n",
      "********************\n",
      "Epoch = 28\n",
      "Number of recorded time steps:  3388\n",
      "********************\n",
      "Epoch = 29\n",
      "Number of recorded time steps:  3509\n",
      "********************\n",
      "Epoch = 30\n",
      "Number of recorded time steps:  3630\n",
      "********************\n"
     ]
    }
   ],
   "source": [
    "# the pivot_grammar flag switches on long-term acquisition between word and role neurons. \n",
    "# Encoding within roles layer is switched off.\n",
    "pivot_grammar = True \n",
    "LT_wc_knowledge = [] # no long-term encoding\n",
    "LT_cc_knowledge = [] # no long-term encoding\n",
    "long_term_learning = True # switches off short-term synaptic plasticity\n",
    "\n",
    "lambda_cc = 20/1000 \n",
    "lambda_cf = 1/1000 \n",
    "\n",
    "sentence = []\n",
    "for n in range(head): sentence.append(cjn.in_in())\n",
    "for n in range(num_steps): sentence.append(cjn.in_in(word=1, role=1)) # the role neuron is activated simultaneously with the word neuron\n",
    "for n in range(num_steps): sentence.append(cjn.in_in(word=2, role=2))\n",
    "for n in range(tail): sentence.append(cjn.in_in())\n",
    "\n",
    "\n",
    "## initialising the working memory model\n",
    "WM_ori = cjn.feature_layer(n_role_neurons = n_role_neurons,\n",
    "                       cc_connectivity_factor = gamma,\n",
    "                       activation_decay = beta,\n",
    "                       LR_c = lambda_cc,\n",
    "                       LR_w = lambda_cf,\n",
    "                       cc_max_connection = epsilon_cc - k_cc,\n",
    "                       cf_max_connection = epsilon_cf - k_cf,\n",
    "                       n_word_neurons = n_word_neurons,\n",
    "                       time_factor = tau,\n",
    "                       LT_wc_knowledge = LT_wc_knowledge,\n",
    "                       cc_learnt_weight = k_L_cc - k_cc,\n",
    "                       cf_learnt_weight = k_L_cf - k_cf,\n",
    "                       input_node_connectivity = W_ff,\n",
    "                       LT_cc_knowledge = LT_cc_knowledge,\n",
    "                       cc_floor_weight = -k_cc, \n",
    "                       cf_floor_weight = -k_cf,\n",
    "                       unified_noise = unified_noise,\n",
    "                       cc_noise = cc_noise,\n",
    "                       wc_noise = wc_noise,\n",
    "                       cf_conj_factor = h,\n",
    "                       mc_connectivity_factor = W_mc,\n",
    "                       mm_connectivity_factor = W_mm,\n",
    "                       pivot_grammar = pivot_grammar,\n",
    "                       long_term_learning = long_term_learning  \n",
    "                      )\n",
    "\n",
    "\n",
    "# running the 30 epochs of long-term acquisition\n",
    "role_neuron_dict, cc_connection_dict, word_neuron_dict, cf_connection_dict, WM_ori, cc_conn_hx, c_act_hx, cf_conn_hx, f_act_hx, cc_long_weights_hx, wc_long_weights_hx, morph_act_hx, wm_conn_hx = cjn.run_model(model=WM_ori, time_steps=len(sentence)*no_periods, sentence=sentence)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c78939ea-6674-4893-9d2d-e3a6824740d0",
   "metadata": {},
   "source": [
    "### Visualisation of long-term encoding\n",
    "\n",
    "We can visualise the gradual learning of long-term semantic knowledge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "af78267d-0993-45d0-ad48-4968daaeb2b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x180 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "connections_to_track = [[1,1],[2,2]] # tracking word to role connections\n",
    "\n",
    "cjn.long_term_encoding_plot(wc_long_weights_hx,connections_to_track)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a095d9cd-b51c-42f2-ba69-ad25e56a240d",
   "metadata": {},
   "source": [
    "### Long-term acquisition of syntactic structure\n",
    "\n",
    "Next, the model is presented with random sentences of the same syntax. <br>\n",
    "The model is expected to picture long-term syntactic knowledge after seeing these sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7fc60832-97a9-40fe-89f0-4a5c0885237d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********************\n",
      "Epoch = 1\n",
      "Number of recorded time steps:  271\n",
      "********************\n",
      "********************\n",
      "Epoch = 1\n",
      "Number of recorded time steps:  271\n",
      "********************\n",
      "********************\n",
      "Epoch = 1\n",
      "Number of recorded time steps:  271\n",
      "********************\n",
      "********************\n",
      "Epoch = 1\n",
      "Number of recorded time steps:  271\n",
      "********************\n",
      "********************\n",
      "Epoch = 1\n",
      "Number of recorded time steps:  271\n",
      "********************\n",
      "********************\n",
      "Epoch = 1\n",
      "Number of recorded time steps:  271\n",
      "********************\n",
      "********************\n",
      "Epoch = 1\n",
      "Number of recorded time steps:  271\n",
      "********************\n",
      "********************\n",
      "Epoch = 1\n",
      "Number of recorded time steps:  271\n",
      "********************\n",
      "********************\n",
      "Epoch = 1\n",
      "Number of recorded time steps:  271\n",
      "********************\n",
      "********************\n",
      "Epoch = 1\n",
      "Number of recorded time steps:  271\n",
      "********************\n",
      "********************\n",
      "Epoch = 1\n",
      "Number of recorded time steps:  271\n",
      "********************\n",
      "********************\n",
      "Epoch = 1\n",
      "Number of recorded time steps:  271\n",
      "********************\n",
      "********************\n",
      "Epoch = 1\n",
      "Number of recorded time steps:  271\n",
      "********************\n",
      "********************\n",
      "Epoch = 1\n",
      "Number of recorded time steps:  271\n",
      "********************\n",
      "********************\n",
      "Epoch = 1\n",
      "Number of recorded time steps:  271\n",
      "********************\n",
      "********************\n",
      "Epoch = 1\n",
      "Number of recorded time steps:  271\n",
      "********************\n",
      "********************\n",
      "Epoch = 1\n",
      "Number of recorded time steps:  271\n",
      "********************\n",
      "********************\n",
      "Epoch = 1\n",
      "Number of recorded time steps:  271\n",
      "********************\n",
      "********************\n",
      "Epoch = 1\n",
      "Number of recorded time steps:  271\n",
      "********************\n",
      "********************\n",
      "Epoch = 1\n",
      "Number of recorded time steps:  271\n",
      "********************\n",
      "********************\n",
      "Epoch = 1\n",
      "Number of recorded time steps:  271\n",
      "********************\n",
      "********************\n",
      "Epoch = 1\n",
      "Number of recorded time steps:  271\n",
      "********************\n",
      "********************\n",
      "Epoch = 1\n",
      "Number of recorded time steps:  271\n",
      "********************\n",
      "********************\n",
      "Epoch = 1\n",
      "Number of recorded time steps:  271\n",
      "********************\n",
      "********************\n",
      "Epoch = 1\n",
      "Number of recorded time steps:  271\n",
      "********************\n",
      "********************\n",
      "Epoch = 1\n",
      "Number of recorded time steps:  271\n",
      "********************\n",
      "********************\n",
      "Epoch = 1\n",
      "Number of recorded time steps:  271\n",
      "********************\n",
      "********************\n",
      "Epoch = 1\n",
      "Number of recorded time steps:  271\n",
      "********************\n",
      "********************\n",
      "Epoch = 1\n",
      "Number of recorded time steps:  271\n",
      "********************\n",
      "********************\n",
      "Epoch = 1\n",
      "Number of recorded time steps:  271\n",
      "********************\n"
     ]
    }
   ],
   "source": [
    "pivot_grammar = False # switch off pivot grammar from before\n",
    "\n",
    "LT_wc_knowledge = [[0,0],[3,1],[6,2],[9,3],[12,4],\n",
    "                   [1,0],[4,1],[7,2],[10,3],[13,4],\n",
    "                   [2,0],[5,1],[8,2],[11,3],[14,4],\n",
    "                  ] # for each role, there are three possible words\n",
    "LT_cc_knowledge = [] # no long-term c-c encoding\n",
    "long_term_learning = True\n",
    "lambda_cc = 20/50 \n",
    "lambda_cf = 1/50 \n",
    "no_periods = 1 # number of epochs is set to 1, because we change the sentence after each epoch\n",
    "\n",
    "## we need to randomly generate the sentences to input\n",
    "sentence_index = np.random.randint(3, size=(5, 30)) # 30 sentences of 5 words each\n",
    "collection_of_sentences = []\n",
    "for j in range(30):\n",
    "    sentence = []\n",
    "    for n in range(head): sentence.append(cjn.in_in())\n",
    "    for n in range(num_steps): sentence.append(cjn.in_in(word=sentence_index[0,j]))\n",
    "    for n in range(num_steps): sentence.append(cjn.in_in(word=sentence_index[1,j]+3))\n",
    "    for n in range(num_steps): sentence.append(cjn.in_in(word=sentence_index[2,j]+6))\n",
    "    for n in range(num_steps): sentence.append(cjn.in_in(word=sentence_index[3,j]+9))\n",
    "    for n in range(num_steps): sentence.append(cjn.in_in(word=sentence_index[4,j]+12))\n",
    "    for n in range(tail): sentence.append(cjn.in_in())\n",
    "    collection_of_sentences.append(sentence)\n",
    "    \n",
    "## initialising the working memory model\n",
    "WM_ori = cjn.feature_layer(n_role_neurons = n_role_neurons,\n",
    "                       cc_connectivity_factor = gamma,\n",
    "                       activation_decay = beta,\n",
    "                       LR_c = lambda_cc,\n",
    "                       LR_w = lambda_cf,\n",
    "                       cc_max_connection = epsilon_cc - k_cc,\n",
    "                       cf_max_connection = epsilon_cf - k_cf,\n",
    "                       n_word_neurons = n_word_neurons,\n",
    "                       time_factor = tau,\n",
    "                       LT_wc_knowledge = LT_wc_knowledge,\n",
    "                       cc_learnt_weight = k_L_cc - k_cc,\n",
    "                       cf_learnt_weight = k_L_cf - k_cf,\n",
    "                       input_node_connectivity = W_ff,\n",
    "                       LT_cc_knowledge = LT_cc_knowledge,\n",
    "                       cc_floor_weight = -k_cc, \n",
    "                       cf_floor_weight = -k_cf,\n",
    "                       unified_noise = unified_noise,\n",
    "                       cc_noise = cc_noise,\n",
    "                       wc_noise = wc_noise,\n",
    "                       cf_conj_factor = h,\n",
    "                       mc_connectivity_factor = W_mc,\n",
    "                       mm_connectivity_factor = W_mm,\n",
    "                       pivot_grammar = pivot_grammar,\n",
    "                       long_term_learning = long_term_learning  \n",
    "                      )\n",
    "\n",
    "# present each of the 30 randomly generated sentences to the network, sequentially, without reset between each epoch.\n",
    "cc_long_weights_hx_collection = []\n",
    "for n in range(30):\n",
    "    role_neuron_dict, cc_connection_dict, word_neuron_dict, cf_connection_dict, WM_ori, cc_conn_hx, c_act_hx, cf_conn_hx, f_act_hx, cc_long_weights_hx, wc_long_weights_hx, morph_act_hx, wm_conn_hx = cjn.run_model(model=WM_ori, time_steps=len(sentence)*no_periods, sentence=collection_of_sentences[n])\n",
    "    cc_long_weights_hx_collection.append(cc_long_weights_hx)\n",
    "cc_long_weights_hx_collection = np.asarray(cc_long_weights_hx_collection)\n",
    "cc_long_weights_hx_collection = cc_long_weights_hx_collection.reshape(-1,10,10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90755652-e4e8-4f8c-bba4-900965c1d7d6",
   "metadata": {},
   "source": [
    "### Visualisation of long-term encoding\n",
    "\n",
    "We can visualise the gradual learning of long-term syntactic knowledge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "19801c7e-11e7-4fa5-ac05-adbabfa0cb3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x180 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "connections_to_track = [[0,1],[1,2],[2,3],[3,4]] # tracking role to role connections\n",
    "\n",
    "cjn.long_term_encoding_plot(cc_long_weights_hx_collection,connections_to_track)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c45df8ce-05f3-4dc5-9c63-dff69c116822",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d650595-860e-42ae-a149-1776bb20f48d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "neuro",
   "language": "python",
   "name": "neuro"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
